# Linear Algebra

1. 벡터와 행렬
	- 샘플의 특징을 백터로 표현
	- 행렬 : 여러 개의 백터를 담음
	- 전치행렬 transpose matrix
	- 특수한 행렬
		- 정사각행렬
		- 대각행렬
		- 단위행렬 : 
		- 대칭행렬 : 특징 전치행렬이 같다
	- Trace : 
	- 행렬 연산 / 행렬의 크기
		- 교환법칙 x
		- 분배, 결합 O
	- 백터의 내적 = (스칼라 값), (벡터의 유사도 판단에 사용)
	- 텐서 : 3차원 이상 구조를 가진 숫자 배열

2. 놈과 유사도
	- 놈 : 벡터와 행렬의 크기 (목적함수 정의에 사용)
		- 벡터의 p차 놈
		- 행렬의 프로베니우스 놈 (규제할 때 사용)
	- 유사도 : 백터의 내적 이용
		- 방향이 달라질수록 값이 작아지므로 유사도 측정에 사용 (단위 벡터 사용)
		- 코사인 유사도 (단위 벡터의 내적)
			- 단점 : 단위벡터를 사용하기 때문에 크기를 무시하게 된다는 단점이 발생

		- 해밍 거리
			- 이진 벡터인 경우 서로 다른 값을 가진 요소의 개수 
			- 
	
3. 퍼셉트론의 해석
	- 분류기 모델
	- 활성화 함수는 계단함수 사용
	- 현대 기계 학습에서 퍼셉트론의 중요성
		- 딥러닝은 다중 퍼셉트론으로 만들어짐 


4. 선형결합과 백터공간
	- 선형결합으로 만들어지는 공간을 벡터공간이라 부름
	- 선형 독립
		- 
		
	- orthogonal(수직)
		- 선형독립이 된다
	- orthonormal (수직, 크기)
	- span : 
	- range 
	- Linear Transform : 
	
5. 역행렬
	- 성질
	- 행렬식 (행렬 A det(A))
		- 기하학적 의미
			- 2차원에서
			- 3차원에서
			- 행렬식은
	- 정부호 행렬
	
6. 행렬 분해
	- 행렬 분해
		- 고유값과 고유벡터로 분해
		- 
	
# Optimization

1. 최적화
	- 기계학습은 최적화 과정이다
	- 목적함수를 최소로 하는 점을 찾는다.
	- 주로 sgd 사용 (데이터 미분)
2. 매개변수 공간
	- 매개변수 공간의 탐색과정 
		- 1) 적절한 모델 선택
		- 2) 목적함수를 정의
		- 3) 모델의 매개변수 공간을 탐색하여 목적함수가 최저가 되는 최적점을 탐색, 찾는 전략 사용

		- -> 특징 공간에서 해야 하는 알을 모델의 매겨변수 공간에서 하는 일로 대치한 셈 

	- 매개변수 공간의 탐색
		- 기계학습은 최적해 찾기 
	- 최적화 문제 해결
		- 낱낱탐색 알고리즘
			- 차원이 높아지면 적용 불가능
		- 무작위 탐색 알고리즘
			- 무작위로 해를 하나 생성
		- 목적함수가 작아지는 방향을 주로 미분으로 찾는다.

3. 미분
	- 미분에 의한 최적화
	- 편미분
	- 독립변수와 종속변수
	- 연쇄법칙(중요)
	- 다층 퍼셉트론은 합성함수
	- 야코비언 행렬
	- 헤시안 행렬
	- 테일러 급수

4. 경사 하강 알고리즘

	

